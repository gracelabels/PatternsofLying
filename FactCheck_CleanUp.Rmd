---
title: "FactCheck_CleanUp"
output: pdf_document
---

```{r load packages, warning=FALSE, message=FALSE, echo = FALSE}
library(tidyverse)
library(knitr)
```

```{r}
v8_fc <- read_csv("v8fc.csv")
```

FactCheck.Org does not have an ordered tier based rating system like PolitiFact and the Washington Post. Rather they have list of descriptive ratings they more commonly assign to claims. FactCheck.Org only publishes claims they find to have some level of false information. Their assesments are decriptive of the nature of the falsehood rather than assessing the level of false information. 

The most common ratings are as follows 

Unsupported
Spins the Facts
Out of Context
Not the Whole Story
No Evidence
Misleading
FALSE
Exaggerates
Distorts the Facts
Cherry Picks

391 claims were assigned one of FC's 10 standard ratings but 120 anomaly claims remained. 
Below is a list of all the textual ratings assigned to claims 
```{r fc textual ratings table}
v8_fc %>%
  group_by(textualRating) %>%
  count() %>%
  arrange(desc(n)) %>%
  kable(caption = "Textual Ratings")
```

We decided not to proceed with analysis for the FactCheck.Org data. The large number of anamolous claims and unordered rating scale made assesment challenging. 